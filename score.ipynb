{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39bd4225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  \n",
    "import json\n",
    "from collections import defaultdict  \n",
    "import os\n",
    "import pandas as pd\n",
    "# from openpyxl import load_workbook\n",
    "def jsonl_to_excel_sheet(jsonl_file, excel_file, sheet_name, prefix_path=\"\"):\n",
    "    jsonl_path = os.path.join('./file', jsonl_file)\n",
    "    rows = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line.strip())\n",
    "            row = {\n",
    "                \"image_path\": prefix_path + data.get(\"image_path\", \"\"),\n",
    "                \"question\": data.get(\"prompt\", \"\"),\n",
    "                \"answer\": data.get(\"answer\", \"\"),\n",
    "                \"category\": \", \".join(data.get(\"category\", [])),\n",
    "                \"l2-category\": data.get(\"subcategory\", \"\"),\n",
    "                \"type\": data.get(\"type\", \"\"),\n",
    "                \"ID\": data.get(\"ID\", \"\"),\n",
    "            }\n",
    "            pred = data.get(\"predict\", \"\")\n",
    "            if isinstance(pred, str):\n",
    "                pred_processed = pred.capitalize()\n",
    "            else:\n",
    "                pred_processed = str(pred)\n",
    "            row[\"prediction\"] = pred_processed\n",
    "            rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.index.name = \"index\"\n",
    "\n",
    "    # try:\n",
    "    #     book = load_workbook(excel_file)\n",
    "    #     if sheet_name in book.sheetnames:\n",
    "    #         # 如果是唯一的sheet，就先创建一个备用空白sheet\n",
    "    #         if len(book.sheetnames) == 1:\n",
    "    #             # 添加备用sheet\n",
    "    #             book.create_sheet(\"_temp_sheet_for_delete_backup_\")\n",
    "    #             book.save(excel_file)  # 保存后才能继续操作\n",
    "    #         # 删除原目标sheet\n",
    "    #         std = book[sheet_name]\n",
    "    #         book.remove(std)\n",
    "    #         book.save(excel_file)\n",
    "\n",
    "    #     with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a') as writer:\n",
    "    #         writer.book = load_workbook(excel_file)  # 重新加载最新的book\n",
    "    #         df.to_excel(writer, sheet_name=sheet_name, index=True)\n",
    "    #         writer.save()\n",
    "\n",
    "    # except FileNotFoundError:\n",
    "    #     # 文件不存在，创建新文件\n",
    "    #     with pd.ExcelWriter(excel_file, engine='openpyxl', mode='w') as writer:\n",
    "    #         df.to_excel(writer, sheet_name=sheet_name, index=True)\n",
    "def evaluate(eval_file):\n",
    "        global COUNT\n",
    "        COUNT = 0\n",
    "        score_file = eval_file.replace('.jsonl', '_score.csv')\n",
    "        score_file = os.path.join('./score', score_file)\n",
    "        def load(file_path):\n",
    "            # 读取jsonl文件\n",
    "            data = []\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    data.append(json.loads(line))\n",
    "            return data\n",
    "        def is_number(s):\n",
    "            try:\n",
    "                float(s)\n",
    "                return True\n",
    "            except ValueError:\n",
    "                pass\n",
    "            return False\n",
    "        def get_blank_metric():  \n",
    "            eval_category_dict = {  \n",
    "                \"unary\": {  \n",
    "                    \"Points-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Line Segment-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Angle-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Triangle-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Circle-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Polygon-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Arc-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                    \"Sector-unary\": [\"Existence\", \"Quantity\", \"Size Property\"],  \n",
    "                },  \n",
    "                \"binary\": {  \n",
    "                    \"Points\": [\"Points\", \"LineSegment\", \"Angle\", \"Triangle\", \"Circle\", \"Polygon\"],  \n",
    "                    \"LineSegment\": [\"LineSegment\", \"Angle\", \"Triangle\", \"Circle\", \"Polygon\"],  \n",
    "                    \"Angle\": [\"Angle\", \"Triangle\", \"Circle\", \"Polygon\"],  \n",
    "                    \"Triangle\": [\"Triangle\", \"Circle\", \"Polygon\"],  \n",
    "                    \"Circle\": [\"Circle\", \"Polygon\"],  \n",
    "                    \"Polygon\": [\"Polygon\"],  \n",
    "                },  \n",
    "                \"answer_type\": [\"choose\", \"free-form\"],  \n",
    "                \"special_case\": [\"wrongprerequisite\", \"not given\", \"normal\"],  \n",
    "                \"id\": [i for i in range(1, 73)],  \n",
    "                \"image\": [\"synthetic\", \"mathverse\"]  \n",
    "            }   \n",
    "\n",
    "            # 初始化空的指标字典  \n",
    "            def initialize_metrics(category_dict):  \n",
    "                metrics = {}  \n",
    "                for key, value in category_dict.items():  \n",
    "                    if isinstance(value, dict):  \n",
    "                        # 如果是字典，则递归调用  \n",
    "                        metrics[key] = initialize_metrics(value)  \n",
    "                    elif isinstance(value, list):  \n",
    "                        # 如果是列表，则为每个元素赋值0  \n",
    "                        metrics[key] = {item: 0 for item in value}  \n",
    "                    else:  \n",
    "                        # 处理其他类型（尽可能保持通用）  \n",
    "                        metrics[key] = 0  \n",
    "                return metrics  \n",
    "            \n",
    "            return initialize_metrics(eval_category_dict) \n",
    "        def is_close_with_ratio(gt_ans, pred_ans, relative_tol=0.01, absolute_tol=1e-6, loose_flag=False):  \n",
    "            if loose_flag and (gt_ans == \"notgiven\" and pred_ans in (\"no\",\"notsure\")):\n",
    "                return True\n",
    "\n",
    "            if isinstance(gt_ans, (int, float)) and isinstance(pred_ans, (int, float)):\n",
    "                # 数字的话看误差\n",
    "                if gt_ans == 0:  \n",
    "                    # 如果 gt_ans 为 0，仅比较绝对误差  \n",
    "                    return abs(gt_ans - pred_ans) <= absolute_tol  \n",
    "                else:  \n",
    "                    # 计算相对误差  \n",
    "                    relative_error = abs(gt_ans - pred_ans) / abs(gt_ans)  \n",
    "                    return relative_error <= relative_tol  \n",
    "            else:\n",
    "                # 字符串严格匹配\n",
    "                return int(gt_ans == pred_ans)\n",
    "        def regularize_answer(ans):  \n",
    "            ans = str(ans).lower().strip().replace(' ', '').replace('\\n', '')\n",
    "            # 去掉句尾的句号\n",
    "            ans = ans[:-1] if ans.endswith('.') else ans\n",
    "            ans = eval(ans) if is_number(ans) else ans\n",
    "            try:\n",
    "                assert ans in [\"yes\", \"no\", \"a\", \"b\", \"c\", \"d\", \"e\", \"wrongprerequisite\", \"notgiven\", \"notsure\"] or isinstance(ans, (int, float))\n",
    "            except:\n",
    "                global COUNT\n",
    "                COUNT += 1\n",
    "                # 返回最大的一个数\n",
    "                return 999\n",
    "            return ans\n",
    "\n",
    "        def process_metric_to_excel(metric_all, excel_file, sheet_name):\n",
    "            data = {\n",
    "                \"Metric\": [],  \n",
    "                \"Category\": [],  \n",
    "                \"Subcategory\": [],  \n",
    "                \"Strict Accuracy\": [],  \n",
    "                \"Loose Accuracy\": [],  \n",
    "                \"Count\": []  \n",
    "            }\n",
    "            for key in metric_all['count']:\n",
    "                if key in ('unary', 'binary'):\n",
    "                    for category, subcategories in metric_all['count'][key].items():\n",
    "                        for subcategory, count in subcategories.items():\n",
    "                            loose_acc = metric_all['loose_c'][key][category][subcategory] / count if count > 0 else '-'\n",
    "                            strict_acc = metric_all['strict_c'][key][category][subcategory] / count if count > 0 else '-'\n",
    "                            data['Metric'].append(key)\n",
    "                            data['Category'].append(category)\n",
    "                            data['Subcategory'].append(subcategory)\n",
    "                            data['Strict Accuracy'].append(strict_acc)\n",
    "                            data['Loose Accuracy'].append(loose_acc)\n",
    "                            data['Count'].append(count)\n",
    "                elif key in ('answer_type', 'special_case', 'id', 'image'):\n",
    "                    for category, count in metric_all['count'][key].items():\n",
    "                        loose_acc = metric_all['loose_c'][key][category] / count if count > 0 else '-'\n",
    "                        strict_acc = metric_all['strict_c'][key][category] / count if count > 0 else '-'\n",
    "                        data['Metric'].append(key)\n",
    "                        data['Category'].append(category)\n",
    "                        data['Subcategory'].append('-')\n",
    "                        data['Strict Accuracy'].append(strict_acc)\n",
    "                        data['Loose Accuracy'].append(loose_acc)\n",
    "                        data['Count'].append(count)\n",
    "\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df[[\"Metric\", \"Category\", \"Subcategory\",  \"Count\", \"Strict Accuracy\", \"Loose Accuracy\"]]\n",
    "\n",
    "            # 判断文件是否存在，若存在则追加sheet，不覆盖其他sheet\n",
    "            # from openpyxl import load_workbook\n",
    "            # try:\n",
    "            #     book = load_workbook(excel_file)\n",
    "            #     with pd.ExcelWriter(excel_file, engine='openpyxl', mode='a') as writer:\n",
    "            #         writer.book = book\n",
    "            #         df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "            # except FileNotFoundError:\n",
    "            #     # 文件不存在时，创建新文件\n",
    "            #     with pd.ExcelWriter(excel_file, engine='openpyxl', mode='w') as writer:\n",
    "            #         df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "            return df\n",
    "        def process_metric_to_dataframe(metric_all):\n",
    "            # 用于存储最终数据的列表\n",
    "            data = {\n",
    "                \"Metric\": [],  \n",
    "                \"Category\": [],  \n",
    "                \"Subcategory\": [],  \n",
    "                \"Strict Accuracy\": [],  \n",
    "                \"Loose Accuracy\": [],  \n",
    "                \"Count\": []  \n",
    "            }\n",
    "            for key in metric_all['count']:\n",
    "                if key in ('unary', 'binary'):\n",
    "                    for category, subcategories in metric_all['count'][key].items():\n",
    "                        for subcategory, count in subcategories.items():\n",
    "                            loose_acc = metric_all['loose_c'][key][category][subcategory] / count if count > 0 else '-'\n",
    "                            strict_acc = metric_all['strict_c'][key][category][subcategory] / count if count > 0 else '-'\n",
    "                            data['Metric'].append(key)\n",
    "                            data['Category'].append(category)\n",
    "                            data['Subcategory'].append(subcategory)\n",
    "                            data['Strict Accuracy'].append(strict_acc)\n",
    "                            data['Loose Accuracy'].append(loose_acc)\n",
    "                            data['Count'].append(count)\n",
    "                elif key in ('answer_type', 'special_case', 'id', 'image'):\n",
    "                    for category, count in metric_all['count'][key].items():\n",
    "                        loose_acc = metric_all['loose_c'][key][category] / count if count > 0 else '-'\n",
    "                        strict_acc = metric_all['strict_c'][key][category] / count if count > 0 else '-'\n",
    "                        data['Metric'].append(key)\n",
    "                        data['Category'].append(category)\n",
    "                        data['Subcategory'].append('-')\n",
    "                        data['Strict Accuracy'].append(strict_acc)\n",
    "                        data['Loose Accuracy'].append(loose_acc)\n",
    "                        data['Count'].append(count)\n",
    "            # 创建 DataFrame\n",
    "            df = pd.DataFrame(data)\n",
    "            # 将数据按 Metric 和 Category 排序  \n",
    "            df = df[[\"Metric\", \"Category\", \"Subcategory\",  \"Count\", \"Strict Accuracy\", \"Loose Accuracy\"]]  \n",
    "            # 保存到score_file\n",
    "            df.to_csv(score_file, index=False)\n",
    "            return df\n",
    "\n",
    "        doc = load(os.path.join('./file', eval_file))  # 读取文件\n",
    "        preds = [x['predict'] for x in doc]\n",
    "        answers = [x['answer'] for x in doc]\n",
    "        metric_all={}\n",
    "        for key in ['strict_c', 'loose_c', 'count']:\n",
    "            metric_all[key] = get_blank_metric()\n",
    "        # zip pred answer\n",
    "        for i, pred, gt in zip(range(len(preds)), preds, answers):  \n",
    "            pred = regularize_answer(pred)\n",
    "            gt = regularize_answer(gt)\n",
    "            \n",
    "\n",
    "            if gt == \"wrongprerequisite\":\n",
    "                # wrong prerequisite特殊处理\n",
    "                metric_all['count']['special_case']['wrongprerequisite'] += 1\n",
    "                metric_all['strict_c']['special_case']['wrongprerequisite'] += pred=='wrongprerequisite'\n",
    "                metric_all['loose_c']['special_case']['wrongprerequisite'] += pred in ('wrongprerequisite', 'notgiven', 'no', 'notsure')\n",
    "                doc[i]['strict'] = pred=='wrongprerequisite'\n",
    "                doc[i]['loose'] = pred in ('wrongprerequisite', 'notgiven', 'no', 'notsure')\n",
    "                continue\n",
    "            category = doc[i]['category']\n",
    "            subcategory = doc[i]['subcategory']\n",
    "            answer_type = doc[i]['type']\n",
    "            ID = doc[i]['ID']\n",
    "            image = doc[i]['image_path']\n",
    "            # 先处理special case\n",
    "\n",
    "            strict_result = is_close_with_ratio(gt, pred)\n",
    "            loose_result = is_close_with_ratio(gt, pred, loose_flag=True)\n",
    "            doc[i]['strict'] = strict_result\n",
    "            doc[i]['loose'] = loose_result\n",
    "\n",
    "            if gt == 'notgiven':\n",
    "                metric_all['count']['special_case']['not given'] += 1\n",
    "                metric_all['strict_c']['special_case']['not given'] += strict_result\n",
    "                metric_all['loose_c']['special_case']['not given'] += loose_result\n",
    "            else:\n",
    "                metric_all['count']['special_case']['normal'] += 1\n",
    "                metric_all['strict_c']['special_case']['normal'] += strict_result\n",
    "                metric_all['loose_c']['special_case']['normal'] += loose_result\n",
    "            # 处理unary binary\n",
    "            if len(category) == 2:\n",
    "                # binary\n",
    "                elem1 = category[0]\n",
    "                elem2 = category[1]\n",
    "                metric_all['count']['binary'][elem1][elem2] += 1\n",
    "                metric_all['strict_c']['binary'][elem1][elem2] += strict_result\n",
    "                metric_all['loose_c']['binary'][elem1][elem2] += loose_result\n",
    "            else:\n",
    "                # unary\n",
    "                metric_all['count']['unary'][category[0]][subcategory] += 1\n",
    "                metric_all['strict_c']['unary'][category[0]][subcategory] += strict_result\n",
    "                metric_all['loose_c']['unary'][category[0]][subcategory] += loose_result\n",
    "            # 处理answer type\n",
    "            metric_all['count']['answer_type'][answer_type] += 1\n",
    "            metric_all['strict_c']['answer_type'][answer_type] += strict_result\n",
    "            metric_all['loose_c']['answer_type'][answer_type] += loose_result\n",
    "            # 处理id\n",
    "            metric_all['count']['id'][ID] += 1\n",
    "            metric_all['strict_c']['id'][ID] += strict_result\n",
    "            metric_all['loose_c']['id'][ID] += loose_result\n",
    "            # 处理image\n",
    "            if 'mathverse' in image:\n",
    "                metric_all['count']['image']['mathverse'] += 1\n",
    "                metric_all['strict_c']['image']['mathverse'] += strict_result\n",
    "                metric_all['loose_c']['image']['mathverse'] += loose_result\n",
    "            else:\n",
    "                metric_all['count']['image']['synthetic'] += 1\n",
    "                metric_all['strict_c']['image']['synthetic'] += strict_result\n",
    "                metric_all['loose_c']['image']['synthetic'] += loose_result\n",
    "        # 计算指标\n",
    "        df = process_metric_to_dataframe(metric_all)\n",
    "        # process_metric_to_excel(metric_all, './score/total_score.xlsx', eval_file.replace('.jsonl', ''))\n",
    "        print(f\"处理完成: {eval_file}，错误数{COUNT}\")\n",
    "\n",
    "        # 存储处理后的数据\n",
    "        output_file = os.path.join('./file_score', eval_file.replace('.jsonl', '_processed.jsonl'))\n",
    "\n",
    "        with open(output_file, 'w', encoding='utf-8') as f_out:\n",
    "            for entry in doc:\n",
    "                f_out.write(json.dumps(entry, ensure_ascii=False) + \"\\n\")\n",
    "        df = None\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6131d399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成: qwen2.5vl_answers.jsonl，错误数0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "eval_file_dir = './file/'\n",
    "# 遍历文件夹\n",
    "eval_file_list = os.listdir(eval_file_dir)\n",
    "# 过滤出以jsonl结尾的文件\n",
    "eval_file_list = [f for f in eval_file_list if f.endswith('.jsonl')]\n",
    "# 遍历文件列表\n",
    "for eval_file in eval_file_list:\n",
    "    eval_file = \"qwen2.5vl_answers.jsonl\"\n",
    "    df = evaluate(eval_file)\n",
    "    print(df)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "score",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
